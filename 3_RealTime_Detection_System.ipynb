{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöë AmbuRoute - Real-Time Detection System\n",
        "## Phase 4: Real-Time Ambulance Detection & Traffic Control\n",
        "\n",
        "This notebook implements the real-time ambulance detection system and traffic signal control logic for the AmbuRoute project.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üö¶ Real-Time Detection System Environment Ready!\n",
            "üîß PyTorch version: 2.8.0+cpu\n",
            "üéÆ CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import time\n",
        "import threading\n",
        "import queue\n",
        "import json\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import YOLOv5 and other ML libraries\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"üö¶ Real-Time Detection System Environment Ready!\")\n",
        "print(f\"üîß PyTorch version: {torch.__version__}\")\n",
        "print(f\"üéÆ CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üö¶ Real-Time Ambulance Detection System\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Real-time detection system ready!\n"
          ]
        }
      ],
      "source": [
        "class RealTimeAmbulanceDetector:\n",
        "    \"\"\"Real-time ambulance detection and traffic control system\"\"\"\n",
        "    \n",
        "    def __init__(self, model_path, confidence_threshold=0.5, iou_threshold=0.6):\n",
        "        self.model_path = model_path\n",
        "        self.confidence_threshold = confidence_threshold\n",
        "        self.iou_threshold = iou_threshold\n",
        "        \n",
        "        # Load the trained model\n",
        "        self.model = YOLO(model_path)\n",
        "        \n",
        "        # Traffic signal states\n",
        "        self.signal_states = {}\n",
        "        self.detection_history = []\n",
        "        self.ambulance_detected = False\n",
        "        self.last_detection_time = None\n",
        "        \n",
        "        # Performance metrics\n",
        "        self.fps_counter = 0\n",
        "        self.start_time = time.time()\n",
        "        self.detection_count = 0\n",
        "        \n",
        "        print(f\"‚úÖ Real-time detector initialized with model: {model_path}\")\n",
        "    \n",
        "    def detect_ambulance(self, frame):\n",
        "        \"\"\"Detect ambulances in a single frame\"\"\"\n",
        "        try:\n",
        "            # Run inference\n",
        "            results = self.model(frame, conf=self.confidence_threshold, iou=self.iou_threshold)\n",
        "            \n",
        "            # Process results\n",
        "            detections = []\n",
        "            for result in results:\n",
        "                if result.boxes is not None:\n",
        "                    for box in result.boxes:\n",
        "                        # Get bounding box coordinates\n",
        "                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "                        confidence = box.conf[0].cpu().numpy()\n",
        "                        class_id = int(box.cls[0].cpu().numpy())\n",
        "                        \n",
        "                        # Only process ambulance detections (class 0)\n",
        "                        if class_id == 0:\n",
        "                            detections.append({\n",
        "                                'bbox': [int(x1), int(y1), int(x2), int(y2)],\n",
        "                                'confidence': float(confidence),\n",
        "                                'class_id': class_id,\n",
        "                                'timestamp': time.time()\n",
        "                            })\n",
        "            \n",
        "            return detections\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error in detection: {e}\")\n",
        "            return []\n",
        "    \n",
        "    def draw_detections(self, frame, detections):\n",
        "        \"\"\"Draw bounding boxes and labels on frame\"\"\"\n",
        "        annotated_frame = frame.copy()\n",
        "        \n",
        "        for detection in detections:\n",
        "            x1, y1, x2, y2 = detection['bbox']\n",
        "            confidence = detection['confidence']\n",
        "            \n",
        "            # Draw bounding box\n",
        "            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            \n",
        "            # Draw label\n",
        "            label = f\"Ambulance: {confidence:.2f}\"\n",
        "            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
        "            cv2.rectangle(annotated_frame, (x1, y1 - label_size[1] - 10), \n",
        "                         (x1 + label_size[0], y1), (0, 255, 0), -1)\n",
        "            cv2.putText(annotated_frame, label, (x1, y1 - 5), \n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
        "        \n",
        "        return annotated_frame\n",
        "    \n",
        "    def update_traffic_signal(self, detections, camera_id=\"default\"):\n",
        "        \"\"\"Update traffic signal based on detections\"\"\"\n",
        "        current_time = time.time()\n",
        "        \n",
        "        if detections:\n",
        "            # Ambulance detected - set signal to GREEN\n",
        "            self.ambulance_detected = True\n",
        "            self.last_detection_time = current_time\n",
        "            self.signal_states[camera_id] = {\n",
        "                'state': 'GREEN',\n",
        "                'timestamp': current_time,\n",
        "                'confidence': max([d['confidence'] for d in detections]),\n",
        "                'reason': 'Ambulance detected'\n",
        "            }\n",
        "            self.detection_count += 1\n",
        "        else:\n",
        "            # No ambulance detected\n",
        "            if self.ambulance_detected and self.last_detection_time:\n",
        "                # Check if enough time has passed since last detection\n",
        "                time_since_detection = current_time - self.last_detection_time\n",
        "                if time_since_detection > 10:  # 10 seconds buffer\n",
        "                    self.ambulance_detected = False\n",
        "                    self.signal_states[camera_id] = {\n",
        "                        'state': 'RED',\n",
        "                        'timestamp': current_time,\n",
        "                        'confidence': 0.0,\n",
        "                        'reason': 'No ambulance detected'\n",
        "                    }\n",
        "            else:\n",
        "                self.signal_states[camera_id] = {\n",
        "                    'state': 'RED',\n",
        "                    'timestamp': current_time,\n",
        "                    'confidence': 0.0,\n",
        "                    'reason': 'No ambulance detected'\n",
        "                }\n",
        "    \n",
        "    def draw_traffic_signal(self, frame, camera_id=\"default\"):\n",
        "        \"\"\"Draw traffic signal status on frame\"\"\"\n",
        "        if camera_id not in self.signal_states:\n",
        "            return frame\n",
        "        \n",
        "        signal_info = self.signal_states[camera_id]\n",
        "        state = signal_info['state']\n",
        "        confidence = signal_info['confidence']\n",
        "        reason = signal_info['reason']\n",
        "        \n",
        "        # Choose colors based on signal state\n",
        "        if state == 'GREEN':\n",
        "            signal_color = (0, 255, 0)  # Green\n",
        "            text_color = (0, 0, 0)  # Black text\n",
        "        else:\n",
        "            signal_color = (0, 0, 255)  # Red\n",
        "            text_color = (255, 255, 255)  # White text\n",
        "        \n",
        "        # Draw signal status box\n",
        "        cv2.rectangle(frame, (10, 10), (400, 120), signal_color, -1)\n",
        "        cv2.rectangle(frame, (10, 10), (400, 120), (255, 255, 255), 2)\n",
        "        \n",
        "        # Add text\n",
        "        cv2.putText(frame, f\"TRAFFIC SIGNAL: {state}\", (20, 40), \n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 1, text_color, 2)\n",
        "        cv2.putText(frame, f\"Confidence: {confidence:.2f}\", (20, 70), \n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, text_color, 2)\n",
        "        cv2.putText(frame, f\"Reason: {reason}\", (20, 100), \n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 2)\n",
        "        \n",
        "        return frame\n",
        "    \n",
        "    def process_video_stream(self, video_source=0, output_path=None, display=True):\n",
        "        \"\"\"Process video stream for real-time detection\"\"\"\n",
        "        print(f\"üé• Starting video stream processing...\")\n",
        "        print(f\"üìπ Video source: {video_source}\")\n",
        "        \n",
        "        # Open video source\n",
        "        cap = cv2.VideoCapture(video_source)\n",
        "        if not cap.isOpened():\n",
        "            print(f\"‚ùå Error: Could not open video source {video_source}\")\n",
        "            return\n",
        "        \n",
        "        # Get video properties\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        \n",
        "        print(f\"üìä Video properties: {width}x{height} @ {fps} FPS\")\n",
        "        \n",
        "        # Setup video writer if output path provided\n",
        "        if output_path:\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "        \n",
        "        frame_count = 0\n",
        "        start_time = time.time()\n",
        "        \n",
        "        try:\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    print(\"üìπ End of video stream\")\n",
        "                    break\n",
        "                \n",
        "                # Detect ambulances\n",
        "                detections = self.detect_ambulance(frame)\n",
        "                \n",
        "                # Update traffic signal\n",
        "                self.update_traffic_signal(detections)\n",
        "                \n",
        "                # Draw detections\n",
        "                annotated_frame = self.draw_detections(frame, detections)\n",
        "                \n",
        "                # Draw traffic signal status\n",
        "                annotated_frame = self.draw_traffic_signal(annotated_frame)\n",
        "                \n",
        "                # Add FPS counter\n",
        "                frame_count += 1\n",
        "                if frame_count % 30 == 0:  # Update FPS every 30 frames\n",
        "                    elapsed_time = time.time() - start_time\n",
        "                    current_fps = frame_count / elapsed_time\n",
        "                    cv2.putText(annotated_frame, f\"FPS: {current_fps:.1f}\", \n",
        "                               (width - 150, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "                \n",
        "                # Write frame to output\n",
        "                if output_path:\n",
        "                    out.write(annotated_frame)\n",
        "                \n",
        "                # Display frame\n",
        "                if display:\n",
        "                    cv2.imshow('AmbuRoute - Real-time Detection', annotated_frame)\n",
        "                    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                        print(\"üõë Stopping video processing...\")\n",
        "                        break\n",
        "                \n",
        "        except KeyboardInterrupt:\n",
        "            print(\"üõë Interrupted by user\")\n",
        "        \n",
        "        finally:\n",
        "            # Cleanup\n",
        "            cap.release()\n",
        "            if output_path:\n",
        "                out.release()\n",
        "            cv2.destroyAllWindows()\n",
        "            \n",
        "            # Print statistics\n",
        "            elapsed_time = time.time() - start_time\n",
        "            avg_fps = frame_count / elapsed_time\n",
        "            print(f\"üìä Processing Statistics:\")\n",
        "            print(f\"   Total frames: {frame_count}\")\n",
        "            print(f\"   Total time: {elapsed_time:.2f} seconds\")\n",
        "            print(f\"   Average FPS: {avg_fps:.2f}\")\n",
        "            print(f\"   Ambulance detections: {self.detection_count}\")\n",
        "    \n",
        "    def process_video_file(self, video_path, output_path=None, display=True):\n",
        "        \"\"\"Process a video file for detection\"\"\"\n",
        "        print(f\"üé¨ Processing video file: {video_path}\")\n",
        "        \n",
        "        if not Path(video_path).exists():\n",
        "            print(f\"‚ùå Video file not found: {video_path}\")\n",
        "            return\n",
        "        \n",
        "        self.process_video_stream(video_path, output_path, display)\n",
        "    \n",
        "    def get_detection_statistics(self):\n",
        "        \"\"\"Get current detection statistics\"\"\"\n",
        "        return {\n",
        "            'total_detections': self.detection_count,\n",
        "            'ambulance_detected': self.ambulance_detected,\n",
        "            'last_detection_time': self.last_detection_time,\n",
        "            'signal_states': self.signal_states,\n",
        "            'fps': self.fps_counter\n",
        "        }\n",
        "\n",
        "# Initialize detector (will be loaded with trained model)\n",
        "print(\"‚úÖ Real-time detection system ready!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
